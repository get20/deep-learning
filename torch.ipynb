{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([4.7, 2.1, -1.6, 4.8, 9.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 4.7000,  2.1000, -1.6000,  4.8000,  9.0000])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[4.7, 2.1, -1.6, 4.8, 9.0],\n",
    "\t\t[5.7, 3.1, -2.6, 3.8, 3.0], \n",
    "\t\t[6.7, 4.1, -3.6, 2.8, 7.0] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4.7000,  2.1000, -1.6000,  4.8000,  9.0000],\n",
       "        [ 5.7000,  3.1000, -2.6000,  3.8000,  3.0000],\n",
       "        [ 6.7000,  4.1000, -3.6000,  2.8000,  7.0000]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 2])\n",
      "tensor([1.4000, 1.3000, 1.5000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None)\n",
    "\n",
    "# sepal length and petal length\n",
    "x = torch.tensor(df.iloc[0:100, [0,2]].values)\n",
    "# as for a numpy array, you can get the dimensions of x\n",
    "print(x.size())\n",
    "# you can select section of your tensor:\n",
    "print(x[1:4,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1,1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.1707, 0.7551, 0.3100, 0.8987, 0.4448, 0.1273],\n",
      "         [0.4940, 0.7014, 0.7462, 0.4582, 0.0157, 0.5052],\n",
      "         [0.3072, 0.3536, 0.5294, 0.5422, 0.4237, 0.8858]],\n",
      "\n",
      "        [[0.4868, 0.8056, 0.7751, 0.3962, 0.4533, 0.7843],\n",
      "         [0.5830, 0.6384, 0.6561, 0.0665, 0.1134, 0.5601],\n",
      "         [0.8551, 0.1018, 0.6087, 0.5613, 0.8326, 0.8187]]])\n",
      "torch.Size([2, 3, 6])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,3,6)\n",
    "print(x)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[[[6.0507e-01, 9.5592e-01, 8.3353e-01],\n",
      "            [4.5524e-01, 5.8892e-01, 9.1036e-02],\n",
      "            [2.6307e-01, 2.4967e-01, 2.9526e-01]],\n",
      "\n",
      "           [[6.2708e-01, 4.9064e-01, 1.8116e-01],\n",
      "            [1.0625e-01, 2.8946e-01, 5.7728e-01],\n",
      "            [7.0302e-01, 6.7090e-02, 4.8598e-01]]],\n",
      "\n",
      "\n",
      "          [[[9.6993e-01, 7.3489e-01, 7.2476e-01],\n",
      "            [3.8947e-01, 6.4147e-01, 7.1055e-01],\n",
      "            [3.0137e-01, 7.9500e-01, 3.9030e-01]],\n",
      "\n",
      "           [[1.3250e-01, 6.1837e-01, 4.0376e-01],\n",
      "            [8.3848e-01, 2.7590e-01, 7.5394e-01],\n",
      "            [3.4233e-01, 9.0548e-01, 3.9815e-01]]],\n",
      "\n",
      "\n",
      "          [[[3.3338e-01, 4.2269e-01, 6.6107e-01],\n",
      "            [2.5169e-01, 6.4614e-01, 8.3311e-01],\n",
      "            [5.3048e-01, 7.6675e-01, 2.3893e-01]],\n",
      "\n",
      "           [[7.4701e-02, 5.8519e-02, 7.2653e-01],\n",
      "            [6.9419e-01, 1.2220e-01, 5.4413e-02],\n",
      "            [1.3860e-02, 8.6398e-01, 1.1561e-01]]],\n",
      "\n",
      "\n",
      "          [[[5.2450e-02, 3.4828e-01, 3.3805e-01],\n",
      "            [7.5081e-01, 4.6635e-01, 7.2349e-01],\n",
      "            [2.2280e-01, 1.0470e-01, 4.3238e-01]],\n",
      "\n",
      "           [[5.1059e-01, 2.7009e-02, 6.0313e-01],\n",
      "            [7.1397e-01, 4.6032e-03, 5.1524e-01],\n",
      "            [6.0175e-01, 5.9530e-01, 7.4905e-01]]],\n",
      "\n",
      "\n",
      "          [[[8.8552e-01, 7.5123e-01, 8.1113e-01],\n",
      "            [4.1706e-01, 4.4797e-01, 4.3303e-01],\n",
      "            [3.8790e-01, 3.4595e-01, 1.9460e-01]],\n",
      "\n",
      "           [[2.2796e-01, 9.1291e-01, 1.8810e-01],\n",
      "            [4.0874e-01, 3.7779e-01, 6.4427e-01],\n",
      "            [3.6653e-01, 6.1445e-01, 1.0480e-02]]],\n",
      "\n",
      "\n",
      "          [[[6.1675e-01, 3.9466e-02, 9.9552e-01],\n",
      "            [8.7317e-01, 1.9273e-01, 1.8270e-01],\n",
      "            [6.7333e-01, 9.2738e-01, 5.4788e-01]],\n",
      "\n",
      "           [[3.7097e-01, 5.7570e-01, 8.3368e-01],\n",
      "            [2.1416e-01, 9.5504e-01, 4.4635e-02],\n",
      "            [1.6645e-01, 9.6663e-01, 7.8180e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[8.3879e-01, 8.8789e-01, 8.5195e-01],\n",
      "            [6.5000e-01, 6.5222e-01, 1.5149e-01],\n",
      "            [7.8281e-01, 8.6099e-01, 2.9840e-01]],\n",
      "\n",
      "           [[2.5803e-01, 2.3160e-03, 1.3711e-01],\n",
      "            [3.7996e-01, 3.8069e-01, 3.5493e-02],\n",
      "            [3.1272e-01, 6.6177e-01, 8.5224e-01]]],\n",
      "\n",
      "\n",
      "          [[[5.5611e-01, 2.1898e-01, 1.4516e-01],\n",
      "            [1.0279e-01, 9.0625e-01, 3.4779e-02],\n",
      "            [7.8708e-01, 5.8688e-01, 4.5236e-01]],\n",
      "\n",
      "           [[4.3286e-02, 3.7573e-01, 3.8467e-01],\n",
      "            [4.5331e-02, 6.9061e-01, 7.3334e-01],\n",
      "            [1.3559e-01, 4.1694e-01, 1.0623e-01]]],\n",
      "\n",
      "\n",
      "          [[[7.3964e-01, 2.6814e-01, 1.7879e-01],\n",
      "            [7.2327e-01, 8.9822e-01, 9.2266e-01],\n",
      "            [5.1028e-01, 9.4214e-01, 8.2214e-01]],\n",
      "\n",
      "           [[4.3856e-01, 8.3719e-01, 1.4648e-01],\n",
      "            [9.6969e-01, 5.2471e-01, 8.0371e-01],\n",
      "            [5.3148e-01, 5.5582e-01, 9.2648e-01]]],\n",
      "\n",
      "\n",
      "          [[[8.6573e-01, 4.8029e-02, 7.3885e-01],\n",
      "            [3.2125e-01, 5.2297e-01, 5.1848e-01],\n",
      "            [3.0063e-02, 2.3683e-01, 3.9472e-01]],\n",
      "\n",
      "           [[9.4155e-01, 7.0042e-01, 7.5321e-01],\n",
      "            [7.8040e-01, 7.3355e-01, 5.9244e-01],\n",
      "            [7.5775e-01, 1.5610e-01, 7.3160e-01]]],\n",
      "\n",
      "\n",
      "          [[[7.4184e-01, 6.9006e-01, 9.2827e-01],\n",
      "            [2.8999e-01, 3.7480e-01, 7.7673e-01],\n",
      "            [7.4076e-01, 7.1646e-02, 3.7158e-04]],\n",
      "\n",
      "           [[8.0574e-01, 3.6742e-01, 3.9598e-02],\n",
      "            [6.8507e-02, 9.2448e-01, 2.6096e-01],\n",
      "            [3.2740e-01, 4.8608e-01, 2.2544e-01]]],\n",
      "\n",
      "\n",
      "          [[[1.6116e-01, 3.6504e-01, 2.2523e-01],\n",
      "            [7.4733e-01, 1.5893e-01, 8.7662e-01],\n",
      "            [9.1557e-01, 2.4874e-01, 9.2457e-01]],\n",
      "\n",
      "           [[4.9543e-01, 5.3559e-02, 4.1471e-01],\n",
      "            [1.4379e-01, 4.1167e-01, 5.8119e-01],\n",
      "            [1.1375e-01, 5.5164e-01, 9.0633e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[8.7562e-01, 7.1577e-01, 2.6791e-01],\n",
      "            [9.0876e-01, 4.6786e-01, 1.2549e-01],\n",
      "            [5.6189e-01, 6.2198e-01, 9.4682e-01]],\n",
      "\n",
      "           [[5.1994e-01, 7.4619e-01, 3.4934e-01],\n",
      "            [6.5618e-01, 9.4413e-01, 7.8185e-01],\n",
      "            [4.2397e-01, 2.7588e-01, 9.8595e-02]]],\n",
      "\n",
      "\n",
      "          [[[2.8121e-01, 4.8836e-01, 9.9770e-01],\n",
      "            [9.0952e-01, 4.9777e-01, 4.5406e-01],\n",
      "            [7.8838e-01, 3.1761e-01, 4.6453e-01]],\n",
      "\n",
      "           [[1.6237e-01, 1.9318e-01, 4.4017e-01],\n",
      "            [1.0528e-01, 2.3363e-01, 4.8461e-01],\n",
      "            [9.5967e-01, 5.0146e-02, 8.0045e-01]]],\n",
      "\n",
      "\n",
      "          [[[8.0916e-01, 7.9165e-01, 7.9977e-01],\n",
      "            [4.2388e-01, 5.3474e-01, 5.6757e-01],\n",
      "            [7.0983e-01, 7.8029e-02, 3.8472e-01]],\n",
      "\n",
      "           [[3.9419e-02, 5.0582e-01, 7.3264e-01],\n",
      "            [4.1299e-01, 7.3500e-01, 8.4245e-01],\n",
      "            [7.5349e-01, 7.2483e-01, 4.3018e-02]]],\n",
      "\n",
      "\n",
      "          [[[3.8450e-01, 4.4169e-01, 2.9863e-01],\n",
      "            [4.7268e-01, 2.6671e-01, 7.0816e-01],\n",
      "            [9.4872e-01, 3.8410e-02, 7.0341e-01]],\n",
      "\n",
      "           [[2.0102e-01, 3.2616e-01, 9.6080e-01],\n",
      "            [1.3072e-01, 1.6076e-01, 8.9003e-03],\n",
      "            [8.8577e-01, 8.5506e-01, 2.5342e-01]]],\n",
      "\n",
      "\n",
      "          [[[5.1358e-01, 9.1602e-01, 4.6867e-01],\n",
      "            [7.6302e-01, 7.9568e-01, 3.2086e-01],\n",
      "            [2.0561e-01, 2.0604e-02, 9.1420e-02]],\n",
      "\n",
      "           [[7.9198e-01, 5.2652e-01, 8.1131e-01],\n",
      "            [9.9409e-01, 1.1800e-02, 3.4742e-02],\n",
      "            [5.7465e-01, 1.6639e-01, 2.6862e-01]]],\n",
      "\n",
      "\n",
      "          [[[2.4567e-01, 4.1894e-01, 6.4608e-01],\n",
      "            [4.4054e-01, 2.4836e-01, 6.9715e-01],\n",
      "            [4.4966e-01, 8.1760e-02, 5.3878e-01]],\n",
      "\n",
      "           [[9.2424e-01, 2.6639e-01, 5.9448e-01],\n",
      "            [7.2526e-01, 3.4888e-01, 9.9794e-01],\n",
      "            [8.8126e-01, 7.3750e-01, 6.6547e-01]]]]],\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "        [[[[[2.8774e-01, 9.8289e-01, 5.9631e-01],\n",
      "            [2.3760e-01, 1.9220e-01, 9.3551e-01],\n",
      "            [2.7948e-01, 8.3093e-01, 7.2914e-01]],\n",
      "\n",
      "           [[7.3027e-01, 1.5867e-01, 6.8885e-01],\n",
      "            [3.2432e-01, 5.2042e-01, 9.8391e-01],\n",
      "            [5.9183e-01, 2.8348e-01, 4.1249e-01]]],\n",
      "\n",
      "\n",
      "          [[[6.5335e-01, 4.4407e-02, 4.0968e-01],\n",
      "            [2.6730e-01, 1.0540e-01, 6.8112e-01],\n",
      "            [5.9381e-01, 4.1294e-01, 9.5932e-01]],\n",
      "\n",
      "           [[3.4837e-01, 4.0905e-01, 2.2461e-01],\n",
      "            [4.1352e-01, 4.3992e-01, 5.7119e-01],\n",
      "            [4.3144e-01, 6.2920e-01, 8.6565e-01]]],\n",
      "\n",
      "\n",
      "          [[[9.3168e-01, 5.0124e-01, 9.3980e-01],\n",
      "            [8.3013e-01, 3.5546e-01, 9.2732e-02],\n",
      "            [4.5925e-01, 4.7045e-01, 4.2748e-01]],\n",
      "\n",
      "           [[1.3598e-01, 7.9849e-01, 3.4773e-02],\n",
      "            [9.7190e-01, 2.7636e-01, 4.9955e-01],\n",
      "            [1.0278e-01, 6.7251e-01, 7.6056e-01]]],\n",
      "\n",
      "\n",
      "          [[[1.8939e-01, 4.8054e-01, 9.2110e-01],\n",
      "            [9.0466e-01, 1.7562e-01, 2.6075e-01],\n",
      "            [9.1069e-01, 7.7680e-02, 2.4862e-01]],\n",
      "\n",
      "           [[5.1632e-01, 4.2332e-01, 9.7671e-01],\n",
      "            [3.9196e-01, 8.4797e-01, 1.2648e-01],\n",
      "            [4.9250e-01, 7.5793e-01, 4.2165e-01]]],\n",
      "\n",
      "\n",
      "          [[[9.9165e-01, 7.0261e-01, 7.3746e-01],\n",
      "            [7.0937e-01, 2.9390e-01, 7.0177e-01],\n",
      "            [6.1108e-01, 9.7224e-01, 1.6165e-01]],\n",
      "\n",
      "           [[3.6175e-01, 1.4699e-01, 1.3686e-01],\n",
      "            [4.9860e-01, 6.6933e-01, 8.9946e-01],\n",
      "            [3.5591e-01, 8.5627e-01, 2.5020e-01]]],\n",
      "\n",
      "\n",
      "          [[[4.3878e-01, 6.0554e-01, 9.4617e-01],\n",
      "            [6.9479e-02, 4.8861e-01, 3.4458e-02],\n",
      "            [1.1086e-01, 9.6360e-01, 7.9894e-01]],\n",
      "\n",
      "           [[3.7345e-01, 4.0320e-01, 7.2283e-01],\n",
      "            [6.9440e-01, 3.5482e-01, 7.4872e-01],\n",
      "            [5.6104e-01, 3.7112e-01, 9.2795e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[7.6051e-02, 1.2086e-01, 7.0202e-02],\n",
      "            [7.0504e-01, 5.0886e-01, 6.2022e-01],\n",
      "            [9.0402e-01, 2.9201e-01, 7.0944e-01]],\n",
      "\n",
      "           [[9.6966e-01, 1.3203e-01, 5.7905e-01],\n",
      "            [8.2973e-01, 8.9083e-01, 6.6319e-01],\n",
      "            [4.9969e-01, 2.7186e-01, 1.6935e-01]]],\n",
      "\n",
      "\n",
      "          [[[1.5344e-02, 7.0697e-01, 5.0770e-01],\n",
      "            [9.1206e-01, 3.7362e-01, 5.7218e-01],\n",
      "            [1.7378e-01, 1.2856e-01, 9.0968e-01]],\n",
      "\n",
      "           [[5.6345e-01, 9.3361e-01, 3.8215e-01],\n",
      "            [9.8929e-01, 5.7261e-01, 5.4670e-01],\n",
      "            [6.2092e-01, 8.2937e-01, 4.0604e-01]]],\n",
      "\n",
      "\n",
      "          [[[9.8407e-01, 3.2689e-01, 2.8198e-01],\n",
      "            [2.4908e-01, 1.5645e-02, 7.2198e-01],\n",
      "            [4.1194e-01, 8.5285e-01, 7.3337e-01]],\n",
      "\n",
      "           [[4.5592e-01, 2.7254e-01, 5.3980e-01],\n",
      "            [3.3279e-01, 1.1379e-01, 9.9698e-01],\n",
      "            [3.7656e-01, 5.6491e-01, 3.2015e-01]]],\n",
      "\n",
      "\n",
      "          [[[1.3975e-01, 6.0486e-01, 9.7267e-01],\n",
      "            [6.5401e-02, 6.1937e-01, 9.3933e-01],\n",
      "            [2.1682e-01, 9.7162e-01, 7.8761e-01]],\n",
      "\n",
      "           [[6.8118e-01, 1.5651e-01, 7.7511e-01],\n",
      "            [2.9820e-01, 8.8016e-01, 7.6021e-01],\n",
      "            [2.4124e-01, 7.2646e-01, 7.0435e-01]]],\n",
      "\n",
      "\n",
      "          [[[2.2782e-01, 3.4646e-01, 3.6574e-01],\n",
      "            [2.3387e-01, 2.5596e-01, 6.6944e-01],\n",
      "            [4.5948e-01, 2.4406e-01, 5.2473e-02]],\n",
      "\n",
      "           [[3.3471e-01, 1.5089e-01, 1.5995e-01],\n",
      "            [9.6082e-01, 9.5979e-01, 2.2439e-01],\n",
      "            [5.3522e-01, 6.1409e-01, 3.1175e-02]]],\n",
      "\n",
      "\n",
      "          [[[5.2247e-01, 6.1079e-01, 8.5011e-01],\n",
      "            [6.6082e-02, 8.4670e-02, 1.1589e-02],\n",
      "            [4.5536e-01, 6.0780e-01, 9.1726e-01]],\n",
      "\n",
      "           [[6.9408e-01, 4.9255e-01, 5.6737e-01],\n",
      "            [9.8138e-01, 2.7869e-02, 9.5249e-01],\n",
      "            [1.1933e-01, 4.3750e-01, 5.1725e-01]]]],\n",
      "\n",
      "\n",
      "\n",
      "         [[[[9.8352e-01, 6.8012e-01, 1.3267e-01],\n",
      "            [2.1031e-01, 6.5556e-01, 8.2392e-01],\n",
      "            [9.7054e-01, 3.5878e-01, 1.6724e-01]],\n",
      "\n",
      "           [[7.3375e-01, 1.7242e-01, 8.8751e-02],\n",
      "            [4.7328e-02, 7.2039e-01, 5.1209e-02],\n",
      "            [5.1437e-03, 3.1097e-01, 7.5236e-01]]],\n",
      "\n",
      "\n",
      "          [[[8.5889e-02, 8.4352e-02, 5.4713e-01],\n",
      "            [9.7946e-01, 6.7860e-01, 2.0362e-01],\n",
      "            [1.8146e-01, 5.9850e-01, 8.0104e-01]],\n",
      "\n",
      "           [[5.4790e-01, 4.7333e-01, 8.5142e-01],\n",
      "            [9.8256e-01, 3.7553e-01, 8.1444e-02],\n",
      "            [5.8446e-01, 5.4736e-01, 6.6108e-01]]],\n",
      "\n",
      "\n",
      "          [[[2.7717e-01, 9.3204e-01, 4.0949e-01],\n",
      "            [9.1238e-01, 3.5666e-01, 8.7579e-01],\n",
      "            [9.8969e-01, 8.4975e-01, 3.0388e-01]],\n",
      "\n",
      "           [[1.7713e-01, 6.3089e-01, 4.7705e-01],\n",
      "            [7.9362e-01, 6.4108e-01, 2.5020e-02],\n",
      "            [6.6881e-01, 8.8633e-01, 6.2294e-01]]],\n",
      "\n",
      "\n",
      "          [[[9.6692e-01, 1.2498e-01, 3.8817e-01],\n",
      "            [7.3630e-01, 4.1326e-01, 6.9064e-01],\n",
      "            [2.8460e-01, 8.9849e-03, 5.0246e-02]],\n",
      "\n",
      "           [[4.8234e-01, 9.1561e-01, 6.4192e-01],\n",
      "            [1.4007e-01, 1.7787e-01, 8.2477e-02],\n",
      "            [7.9717e-01, 3.5035e-01, 2.3174e-01]]],\n",
      "\n",
      "\n",
      "          [[[7.7967e-01, 2.6839e-01, 6.4358e-01],\n",
      "            [7.7141e-01, 8.9847e-01, 7.9143e-01],\n",
      "            [2.4470e-01, 7.1564e-01, 6.4129e-01]],\n",
      "\n",
      "           [[6.2218e-01, 3.9012e-01, 9.5127e-01],\n",
      "            [8.7634e-01, 4.3580e-01, 1.0379e-01],\n",
      "            [1.9244e-01, 6.0720e-01, 1.6204e-01]]],\n",
      "\n",
      "\n",
      "          [[[4.3733e-01, 8.4714e-01, 4.0275e-01],\n",
      "            [5.8602e-02, 8.7232e-01, 7.2478e-01],\n",
      "            [4.6114e-01, 1.9262e-01, 7.7393e-01]],\n",
      "\n",
      "           [[6.9894e-01, 3.5710e-01, 5.2703e-01],\n",
      "            [3.3525e-01, 3.5257e-01, 8.2854e-01],\n",
      "            [5.8317e-01, 8.4198e-01, 4.5986e-01]]]]]])\n",
      "torch.Size([2, 3, 6, 2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,3,6,2,3,3)\n",
    "print(x)\n",
    "print(x.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9956, 0.4094, 0.7256],\n",
      "        [0.6317, 0.6858, 0.3512]])\n",
      "[[0.9956487  0.40939695 0.72563267]\n",
      " [0.6316928  0.68578583 0.35118884]]\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,3)\n",
    "print(x)\n",
    "print(x.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5941, 0.7073, 0.2687],\n",
      "        [0.8277, 0.1068, 0.5904]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,3,requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1486, 1.6160, 0.7879],\n",
      "        [0.1973, 0.6286, 0.9446]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(2,3,requires_grad=True)\n",
    "y = x*x + 5\n",
    "out = y.sum()\n",
    "out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data', header=None)\n",
    "print(type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0           1           2           3\n",
       "count  150.000000  150.000000  150.000000  150.000000\n",
       "mean     5.843333    3.054000    3.758667    1.198667\n",
       "std      0.828066    0.433594    1.764420    0.763161\n",
       "min      4.300000    2.000000    1.000000    0.100000\n",
       "25%      5.100000    2.800000    1.600000    0.300000\n",
       "50%      5.800000    3.000000    4.350000    1.300000\n",
       "75%      6.400000    3.300000    5.100000    1.800000\n",
       "max      7.900000    4.400000    6.900000    2.500000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.4</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.9</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>6.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>4.9</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.7</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>7.7</td>\n",
       "      <td>2.6</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>6.1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>5.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>5.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>6.4</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.3</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>5.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>5.2</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>7.2</td>\n",
       "      <td>3.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>5.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>7.9</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>7.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>6.7</td>\n",
       "      <td>2.2</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.4</td>\n",
       "      <td>3.9</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>5.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0    1    2    3                4\n",
       "60   5.0  2.0  3.5  1.0  Iris-versicolor\n",
       "62   6.0  2.2  4.0  1.0  Iris-versicolor\n",
       "119  6.0  2.2  5.0  1.5   Iris-virginica\n",
       "68   6.2  2.2  4.5  1.5  Iris-versicolor\n",
       "41   4.5  2.3  1.3  0.3      Iris-setosa\n",
       "53   5.5  2.3  4.0  1.3  Iris-versicolor\n",
       "93   5.0  2.3  3.3  1.0  Iris-versicolor\n",
       "87   6.3  2.3  4.4  1.3  Iris-versicolor\n",
       "81   5.5  2.4  3.7  1.0  Iris-versicolor\n",
       "80   5.5  2.4  3.8  1.1  Iris-versicolor\n",
       "57   4.9  2.4  3.3  1.0  Iris-versicolor\n",
       "72   6.3  2.5  4.9  1.5  Iris-versicolor\n",
       "146  6.3  2.5  5.0  1.9   Iris-virginica\n",
       "98   5.1  2.5  3.0  1.1  Iris-versicolor\n",
       "113  5.7  2.5  5.0  2.0   Iris-virginica\n",
       "108  6.7  2.5  5.8  1.8   Iris-virginica\n",
       "69   5.6  2.5  3.9  1.1  Iris-versicolor\n",
       "89   5.5  2.5  4.0  1.3  Iris-versicolor\n",
       "106  4.9  2.5  4.5  1.7   Iris-virginica\n",
       "92   5.8  2.6  4.0  1.2  Iris-versicolor\n",
       "79   5.7  2.6  3.5  1.0  Iris-versicolor\n",
       "90   5.5  2.6  4.4  1.2  Iris-versicolor\n",
       "118  7.7  2.6  6.9  2.3   Iris-virginica\n",
       "134  6.1  2.6  5.6  1.4   Iris-virginica\n",
       "101  5.8  2.7  5.1  1.9   Iris-virginica\n",
       "94   5.6  2.7  4.2  1.3  Iris-versicolor\n",
       "59   5.2  2.7  3.9  1.4  Iris-versicolor\n",
       "111  6.4  2.7  5.3  1.9   Iris-virginica\n",
       "82   5.8  2.7  3.9  1.2  Iris-versicolor\n",
       "67   5.8  2.7  4.1  1.0  Iris-versicolor\n",
       "..   ...  ...  ...  ...              ...\n",
       "85   6.0  3.4  4.5  1.6  Iris-versicolor\n",
       "39   5.1  3.4  1.5  0.2      Iris-setosa\n",
       "31   5.4  3.4  1.5  0.4      Iris-setosa\n",
       "20   5.4  3.4  1.7  0.2      Iris-setosa\n",
       "148  6.2  3.4  5.4  2.3   Iris-virginica\n",
       "26   5.0  3.4  1.6  0.4      Iris-setosa\n",
       "43   5.0  3.5  1.6  0.6      Iris-setosa\n",
       "40   5.0  3.5  1.3  0.3      Iris-setosa\n",
       "36   5.5  3.5  1.3  0.2      Iris-setosa\n",
       "27   5.2  3.5  1.5  0.2      Iris-setosa\n",
       "0    5.1  3.5  1.4  0.2      Iris-setosa\n",
       "17   5.1  3.5  1.4  0.3      Iris-setosa\n",
       "22   4.6  3.6  1.0  0.2      Iris-setosa\n",
       "109  7.2  3.6  6.1  2.5   Iris-virginica\n",
       "4    5.0  3.6  1.4  0.2      Iris-setosa\n",
       "10   5.4  3.7  1.5  0.2      Iris-setosa\n",
       "48   5.3  3.7  1.5  0.2      Iris-setosa\n",
       "21   5.1  3.7  1.5  0.4      Iris-setosa\n",
       "131  7.9  3.8  6.4  2.0   Iris-virginica\n",
       "117  7.7  3.8  6.7  2.2   Iris-virginica\n",
       "46   5.1  3.8  1.6  0.2      Iris-setosa\n",
       "44   5.1  3.8  1.9  0.4      Iris-setosa\n",
       "18   5.7  3.8  1.7  0.3      Iris-setosa\n",
       "19   5.1  3.8  1.5  0.3      Iris-setosa\n",
       "5    5.4  3.9  1.7  0.4      Iris-setosa\n",
       "16   5.4  3.9  1.3  0.4      Iris-setosa\n",
       "14   5.8  4.0  1.2  0.2      Iris-setosa\n",
       "32   5.2  4.1  1.5  0.1      Iris-setosa\n",
       "33   5.5  4.2  1.4  0.2      Iris-setosa\n",
       "15   5.7  4.4  1.5  0.4      Iris-setosa\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values(by=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Perceptron(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\t    # We initialize using the base \n",
    "\t\t# class initialization\n",
    "\t\t# super() lets you avoid referring to the base class explicitly.\n",
    "        super().__init__()\n",
    "\t\t# we define a layer using Linear model\n",
    "\t\t# as we will apply a linear transformation to our inputs\n",
    "\t\t# the first parameter is the number of neurons in the input layer\n",
    "\t\t# and the second parameter is the number of outputs (here 1).\n",
    "        self.fl = torch.nn.Linear(1,1)\n",
    "\t\n",
    "    def forward(self, x):\n",
    "        x = self.fl(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(\n",
      "  (fl): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "neural_network = Perceptron()\n",
    "print(neural_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.6732]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.6753], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(neural_network.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6006], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, requires_grad=True)\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2710], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out = neural_network(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.4928628"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.6732 * -0.2710 - 0.6753"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.27097608"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-0.6732 * -0.6006 - 0.6753"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.27097608"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(-0.6732 * -0.6006) - 0.6753"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2710], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out = neural_network(input)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_function = torch.nn.MSELoss()\n",
    "   \n",
    "perceptron_optimizer = torch.optim.SGD(neural_network.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (50,) and (51, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-512850578d6b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#predict values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mneural_network\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m51\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearning/lib/python3.6/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2811\u001b[0m     return gca().plot(\n\u001b[1;32m   2812\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2813\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearning/lib/python3.6/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1808\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1809\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1810\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1812\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m/anaconda3/envs/deeplearning/lib/python3.6/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1609\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1610\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1611\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1612\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearning/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearning/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/deeplearning/lib/python3.6/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 231\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (50,) and (51, 1)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "data = torch.zeros(51,1)\n",
    "for i in range(50):\n",
    "    plt.plot(i+1,(i+1)*3,marker='o', color='b')\n",
    "    data[i] = float(i+1.)\n",
    "#predict values\n",
    "Y=neural_network(data)\n",
    "plt.plot(range(1,51),Y.detach().numpy())\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nueral_network' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-fbccc6747a1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnueral_network\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'nueral_network' is not defined"
     ]
    }
   ],
   "source": [
    "print(list(nueral_network.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Perceptron(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "\t    # We initialize using the base \n",
    "\t\t# class initialization\n",
    "\t\t# super() lets you avoid referring to the base class explicitly.\n",
    "        super().__init__()\n",
    "\t\t# we define a layer using Linear model\n",
    "\t\t# as we will apply a linear transformation to our inputs\n",
    "\t\t# the first parameter is the number of neurons in the input layer\n",
    "\t\t# and the second parameter is the number of outputs (here 1).\n",
    "        self.fl = torch.nn.Linear(1,1)\n",
    "\t\n",
    "    def forward(self, x):\n",
    "        x = self.fl(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron(\n",
      "  (fl): Linear(in_features=1, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "neural_network = Perceptron()\n",
    "print(neural_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-41-30e60e263cb5>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-41-30e60e263cb5>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    (fl): Linear(in_features=1, out_features=1, bias = True)\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Perceptron(\n",
    "  (fl): Linear(in_features=1, out_features=1, bias = True)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Parameter containing:\n",
      "tensor([[-0.9446]], requires_grad=True), Parameter containing:\n",
      "tensor([-0.7555], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(list(neural_network.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.6262], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "input = torch.randn(1, requires_grad=True)\n",
    "print(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.2361], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "out = neural_network(input)\n",
    "print(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_function = torch.nn.MSELoss()\n",
    "   \n",
    "perceptron_optimizer = torch.optim.SGD(neural_network.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 - loss: 22.090181350708008\n",
      "Epoch 1 - loss: 0.0004509652790147811\n",
      "Epoch 2 - loss: 0.06032075732946396\n",
      "Epoch 3 - loss: 0.0652519091963768\n",
      "Epoch 4 - loss: 0.06272025406360626\n",
      "Epoch 5 - loss: 0.05987771973013878\n",
      "Epoch 6 - loss: 0.057141099125146866\n",
      "Epoch 7 - loss: 0.05452793091535568\n",
      "Epoch 8 - loss: 0.05203431472182274\n",
      "Epoch 9 - loss: 0.049654826521873474\n",
      "Epoch 10 - loss: 0.04738394916057587\n",
      "Epoch 11 - loss: 0.045217208564281464\n",
      "Epoch 12 - loss: 0.043149396777153015\n",
      "Epoch 13 - loss: 0.041176024824380875\n",
      "Epoch 14 - loss: 0.039293158799409866\n",
      "Epoch 15 - loss: 0.037496261298656464\n",
      "Epoch 16 - loss: 0.03578154742717743\n",
      "Epoch 17 - loss: 0.03414519131183624\n",
      "Epoch 18 - loss: 0.03258379176259041\n",
      "Epoch 19 - loss: 0.031093645840883255\n",
      "Epoch 20 - loss: 0.029671799391508102\n",
      "Epoch 21 - loss: 0.02831491082906723\n",
      "Epoch 22 - loss: 0.02702002413570881\n",
      "Epoch 23 - loss: 0.025784378871321678\n",
      "Epoch 24 - loss: 0.024605244398117065\n",
      "Epoch 25 - loss: 0.02348007634282112\n",
      "Epoch 26 - loss: 0.022406212985515594\n",
      "Epoch 27 - loss: 0.021381674334406853\n",
      "Epoch 28 - loss: 0.020403919741511345\n",
      "Epoch 29 - loss: 0.019470734521746635\n",
      "Epoch 30 - loss: 0.018580378964543343\n",
      "Epoch 31 - loss: 0.01773066446185112\n",
      "Epoch 32 - loss: 0.016919871792197227\n",
      "Epoch 33 - loss: 0.016146106645464897\n",
      "Epoch 34 - loss: 0.015407727099955082\n",
      "Epoch 35 - loss: 0.014703160151839256\n",
      "Epoch 36 - loss: 0.014030780643224716\n",
      "Epoch 37 - loss: 0.013389084488153458\n",
      "Epoch 38 - loss: 0.01277684886008501\n",
      "Epoch 39 - loss: 0.012192626483738422\n",
      "Epoch 40 - loss: 0.011634930036962032\n",
      "Epoch 41 - loss: 0.011102946475148201\n",
      "Epoch 42 - loss: 0.010595188476145267\n",
      "Epoch 43 - loss: 0.010110673494637012\n",
      "Epoch 44 - loss: 0.009648267179727554\n",
      "Epoch 45 - loss: 0.009207021445035934\n",
      "Epoch 46 - loss: 0.008786022663116455\n",
      "Epoch 47 - loss: 0.008384260348975658\n",
      "Epoch 48 - loss: 0.008000855334103107\n",
      "Epoch 49 - loss: 0.007635002490133047\n",
      "Epoch 50 - loss: 0.0072858091443777084\n",
      "Epoch 51 - loss: 0.006952619180083275\n",
      "Epoch 52 - loss: 0.006634721532464027\n",
      "Epoch 53 - loss: 0.006331317592412233\n",
      "Epoch 54 - loss: 0.00604179548099637\n",
      "Epoch 55 - loss: 0.005765455309301615\n",
      "Epoch 56 - loss: 0.005501771345734596\n",
      "Epoch 57 - loss: 0.005250200629234314\n",
      "Epoch 58 - loss: 0.005010117776691914\n",
      "Epoch 59 - loss: 0.004780960269272327\n",
      "Epoch 60 - loss: 0.00456238305196166\n",
      "Epoch 61 - loss: 0.004353732336312532\n",
      "Epoch 62 - loss: 0.004154635593295097\n",
      "Epoch 63 - loss: 0.003964610863476992\n",
      "Epoch 64 - loss: 0.003783314721658826\n",
      "Epoch 65 - loss: 0.0036103001330047846\n",
      "Epoch 66 - loss: 0.0034452241379767656\n",
      "Epoch 67 - loss: 0.0032876734621822834\n",
      "Epoch 68 - loss: 0.0031373612582683563\n",
      "Epoch 69 - loss: 0.002993878908455372\n",
      "Epoch 70 - loss: 0.0028569395653903484\n",
      "Epoch 71 - loss: 0.0027262673247605562\n",
      "Epoch 72 - loss: 0.002601644489914179\n",
      "Epoch 73 - loss: 0.002482644747942686\n",
      "Epoch 74 - loss: 0.002369099063798785\n",
      "Epoch 75 - loss: 0.0022607948631048203\n",
      "Epoch 76 - loss: 0.002157393842935562\n",
      "Epoch 77 - loss: 0.0020587490871548653\n",
      "Epoch 78 - loss: 0.0019645888824015856\n",
      "Epoch 79 - loss: 0.0018747792346403003\n",
      "Epoch 80 - loss: 0.0017890064045786858\n",
      "Epoch 81 - loss: 0.0017072116024792194\n",
      "Epoch 82 - loss: 0.0016291391802951694\n",
      "Epoch 83 - loss: 0.0015546232461929321\n",
      "Epoch 84 - loss: 0.0014835407491773367\n",
      "Epoch 85 - loss: 0.001415700069628656\n",
      "Epoch 86 - loss: 0.001350918784737587\n",
      "Epoch 87 - loss: 0.0012891435762867332\n",
      "Epoch 88 - loss: 0.001230201916769147\n",
      "Epoch 89 - loss: 0.001173945958726108\n",
      "Epoch 90 - loss: 0.0011202831519767642\n",
      "Epoch 91 - loss: 0.0010690289782360196\n",
      "Epoch 92 - loss: 0.0010201320983469486\n",
      "Epoch 93 - loss: 0.0009734804043546319\n",
      "Epoch 94 - loss: 0.0009289521258324385\n",
      "Epoch 95 - loss: 0.0008864881237968802\n",
      "Epoch 96 - loss: 0.0008459464879706502\n",
      "Epoch 97 - loss: 0.0008072612108662724\n",
      "Epoch 98 - loss: 0.0007703544688411057\n",
      "Epoch 99 - loss: 0.0007351126405410469\n"
     ]
    }
   ],
   "source": [
    "inputs = [(1.,3.), (2.,6.), (3.,9.), (4.,12.), (5.,15.), (6.,18.)]\n",
    "for epoch in range(100):\n",
    "    for i, data in enumerate(inputs):\n",
    "        X, Y = iter(data)\n",
    "        X = torch.tensor([X], requires_grad=True)\n",
    "\t\t# output does not need to have requires_grad=True\n",
    "        Y = torch.tensor([Y], requires_grad=False)\n",
    "\t\t# Initialize optimizer\n",
    "        perceptron_optimizer.zero_grad()\n",
    "        outputs = neural_network(X)\n",
    "        cost = cost_function(outputs, Y)\n",
    "        cost.backward()\n",
    "        perceptron_optimizer.step()\n",
    "        if (i % 10 == 0):\n",
    "            print(\"Epoch {} - loss: {}\".format(epoch, cost.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  3.0265],\n",
      "        [  6.0206],\n",
      "        [  9.0148],\n",
      "        [ 12.0089],\n",
      "        [ 15.0030],\n",
      "        [ 17.9972],\n",
      "        [ 20.9913],\n",
      "        [ 23.9854],\n",
      "        [ 26.9796],\n",
      "        [ 29.9737],\n",
      "        [ 32.9678],\n",
      "        [ 35.9620],\n",
      "        [ 38.9561],\n",
      "        [ 41.9502],\n",
      "        [ 44.9444],\n",
      "        [ 47.9385],\n",
      "        [ 50.9326],\n",
      "        [ 53.9268],\n",
      "        [ 56.9209],\n",
      "        [ 59.9151],\n",
      "        [ 62.9092],\n",
      "        [ 65.9033],\n",
      "        [ 68.8975],\n",
      "        [ 71.8916],\n",
      "        [ 74.8857],\n",
      "        [ 77.8799],\n",
      "        [ 80.8740],\n",
      "        [ 83.8681],\n",
      "        [ 86.8623],\n",
      "        [ 89.8564],\n",
      "        [ 92.8505],\n",
      "        [ 95.8447],\n",
      "        [ 98.8388],\n",
      "        [101.8329],\n",
      "        [104.8271],\n",
      "        [107.8212],\n",
      "        [110.8153],\n",
      "        [113.8095],\n",
      "        [116.8036],\n",
      "        [119.7977],\n",
      "        [122.7919],\n",
      "        [125.7860],\n",
      "        [128.7802],\n",
      "        [131.7743],\n",
      "        [134.7684],\n",
      "        [137.7626],\n",
      "        [140.7567],\n",
      "        [143.7508],\n",
      "        [146.7450],\n",
      "        [149.7391]], grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "data = torch.zeros(50,1)\n",
    "for i in range(50):\n",
    "    plt.plot(i+1,(i+1)*3,marker='o', color='b')\n",
    "    data[i] = float(i+1.)\n",
    "#predict values\n",
    "Y=neural_network(data)\n",
    "plt.plot(range(1,51),Y.detach().numpy())\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#defining class for 1 input and one output\n",
    "class MyDeepLearning(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer1=torch.nn.Linear(1,1)\n",
    "        \n",
    "    def forward(self,input):\n",
    "        return self.layer1(input)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_function=torch.nn.MSELoss() #cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "nueral_net=MyDeepLearning()\n",
    "myoptimizer=torch.optim.SGD(nueral_net.parameters(), lr=0.01)#optimizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.7797], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "n=torch.randn(1, requires_grad=True)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(13.2294, grad_fn=<MseLossBackward>)\n",
      "1 tensor(12.3921, grad_fn=<MseLossBackward>)\n",
      "2 tensor(11.6079, grad_fn=<MseLossBackward>)\n",
      "3 tensor(10.8733, grad_fn=<MseLossBackward>)\n",
      "4 tensor(10.1852, grad_fn=<MseLossBackward>)\n",
      "5 tensor(9.5406, grad_fn=<MseLossBackward>)\n",
      "6 tensor(8.9368, grad_fn=<MseLossBackward>)\n",
      "7 tensor(8.3713, grad_fn=<MseLossBackward>)\n",
      "8 tensor(7.8415, grad_fn=<MseLossBackward>)\n",
      "9 tensor(7.3452, grad_fn=<MseLossBackward>)\n",
      "10 tensor(6.8804, grad_fn=<MseLossBackward>)\n",
      "11 tensor(6.4450, grad_fn=<MseLossBackward>)\n",
      "12 tensor(6.0371, grad_fn=<MseLossBackward>)\n",
      "13 tensor(5.6550, grad_fn=<MseLossBackward>)\n",
      "14 tensor(5.2972, grad_fn=<MseLossBackward>)\n",
      "15 tensor(4.9619, grad_fn=<MseLossBackward>)\n",
      "16 tensor(4.6479, grad_fn=<MseLossBackward>)\n",
      "17 tensor(4.3538, grad_fn=<MseLossBackward>)\n",
      "18 tensor(4.0782, grad_fn=<MseLossBackward>)\n",
      "19 tensor(3.8201, grad_fn=<MseLossBackward>)\n",
      "20 tensor(3.5784, grad_fn=<MseLossBackward>)\n",
      "21 tensor(3.3519, grad_fn=<MseLossBackward>)\n",
      "22 tensor(3.1398, grad_fn=<MseLossBackward>)\n",
      "23 tensor(2.9411, grad_fn=<MseLossBackward>)\n",
      "24 tensor(2.7550, grad_fn=<MseLossBackward>)\n",
      "25 tensor(2.5806, grad_fn=<MseLossBackward>)\n",
      "26 tensor(2.4173, grad_fn=<MseLossBackward>)\n",
      "27 tensor(2.2643, grad_fn=<MseLossBackward>)\n",
      "28 tensor(2.1210, grad_fn=<MseLossBackward>)\n",
      "29 tensor(1.9868, grad_fn=<MseLossBackward>)\n",
      "30 tensor(1.8611, grad_fn=<MseLossBackward>)\n",
      "31 tensor(1.7433, grad_fn=<MseLossBackward>)\n",
      "32 tensor(1.6330, grad_fn=<MseLossBackward>)\n",
      "33 tensor(1.5296, grad_fn=<MseLossBackward>)\n",
      "34 tensor(1.4328, grad_fn=<MseLossBackward>)\n",
      "35 tensor(1.3421, grad_fn=<MseLossBackward>)\n",
      "36 tensor(1.2572, grad_fn=<MseLossBackward>)\n",
      "37 tensor(1.1776, grad_fn=<MseLossBackward>)\n",
      "38 tensor(1.1031, grad_fn=<MseLossBackward>)\n",
      "39 tensor(1.0333, grad_fn=<MseLossBackward>)\n",
      "40 tensor(0.9679, grad_fn=<MseLossBackward>)\n",
      "41 tensor(0.9067, grad_fn=<MseLossBackward>)\n",
      "42 tensor(0.8493, grad_fn=<MseLossBackward>)\n",
      "43 tensor(0.7955, grad_fn=<MseLossBackward>)\n",
      "44 tensor(0.7452, grad_fn=<MseLossBackward>)\n",
      "45 tensor(0.6980, grad_fn=<MseLossBackward>)\n",
      "46 tensor(0.6539, grad_fn=<MseLossBackward>)\n",
      "47 tensor(0.6125, grad_fn=<MseLossBackward>)\n",
      "48 tensor(0.5737, grad_fn=<MseLossBackward>)\n",
      "49 tensor(0.5374, grad_fn=<MseLossBackward>)\n",
      "50 tensor(0.5034, grad_fn=<MseLossBackward>)\n",
      "51 tensor(0.4715, grad_fn=<MseLossBackward>)\n",
      "52 tensor(0.4417, grad_fn=<MseLossBackward>)\n",
      "53 tensor(0.4137, grad_fn=<MseLossBackward>)\n",
      "54 tensor(0.3876, grad_fn=<MseLossBackward>)\n",
      "55 tensor(0.3630, grad_fn=<MseLossBackward>)\n",
      "56 tensor(0.3401, grad_fn=<MseLossBackward>)\n",
      "57 tensor(0.3185, grad_fn=<MseLossBackward>)\n",
      "58 tensor(0.2984, grad_fn=<MseLossBackward>)\n",
      "59 tensor(0.2795, grad_fn=<MseLossBackward>)\n",
      "60 tensor(0.2618, grad_fn=<MseLossBackward>)\n",
      "61 tensor(0.2452, grad_fn=<MseLossBackward>)\n",
      "62 tensor(0.2297, grad_fn=<MseLossBackward>)\n",
      "63 tensor(0.2152, grad_fn=<MseLossBackward>)\n",
      "64 tensor(0.2016, grad_fn=<MseLossBackward>)\n",
      "65 tensor(0.1888, grad_fn=<MseLossBackward>)\n",
      "66 tensor(0.1769, grad_fn=<MseLossBackward>)\n",
      "67 tensor(0.1657, grad_fn=<MseLossBackward>)\n",
      "68 tensor(0.1552, grad_fn=<MseLossBackward>)\n",
      "69 tensor(0.1454, grad_fn=<MseLossBackward>)\n",
      "70 tensor(0.1362, grad_fn=<MseLossBackward>)\n",
      "71 tensor(0.1275, grad_fn=<MseLossBackward>)\n",
      "72 tensor(0.1195, grad_fn=<MseLossBackward>)\n",
      "73 tensor(0.1119, grad_fn=<MseLossBackward>)\n",
      "74 tensor(0.1048, grad_fn=<MseLossBackward>)\n",
      "75 tensor(0.0982, grad_fn=<MseLossBackward>)\n",
      "76 tensor(0.0920, grad_fn=<MseLossBackward>)\n",
      "77 tensor(0.0862, grad_fn=<MseLossBackward>)\n",
      "78 tensor(0.0807, grad_fn=<MseLossBackward>)\n",
      "79 tensor(0.0756, grad_fn=<MseLossBackward>)\n",
      "80 tensor(0.0708, grad_fn=<MseLossBackward>)\n",
      "81 tensor(0.0663, grad_fn=<MseLossBackward>)\n",
      "82 tensor(0.0621, grad_fn=<MseLossBackward>)\n",
      "83 tensor(0.0582, grad_fn=<MseLossBackward>)\n",
      "84 tensor(0.0545, grad_fn=<MseLossBackward>)\n",
      "85 tensor(0.0511, grad_fn=<MseLossBackward>)\n",
      "86 tensor(0.0478, grad_fn=<MseLossBackward>)\n",
      "87 tensor(0.0448, grad_fn=<MseLossBackward>)\n",
      "88 tensor(0.0420, grad_fn=<MseLossBackward>)\n",
      "89 tensor(0.0393, grad_fn=<MseLossBackward>)\n",
      "90 tensor(0.0368, grad_fn=<MseLossBackward>)\n",
      "91 tensor(0.0345, grad_fn=<MseLossBackward>)\n",
      "92 tensor(0.0323, grad_fn=<MseLossBackward>)\n",
      "93 tensor(0.0303, grad_fn=<MseLossBackward>)\n",
      "94 tensor(0.0284, grad_fn=<MseLossBackward>)\n",
      "95 tensor(0.0266, grad_fn=<MseLossBackward>)\n",
      "96 tensor(0.0249, grad_fn=<MseLossBackward>)\n",
      "97 tensor(0.0233, grad_fn=<MseLossBackward>)\n",
      "98 tensor(0.0218, grad_fn=<MseLossBackward>)\n",
      "99 tensor(0.0204, grad_fn=<MseLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "y=torch.randn(1, requires_grad=False)\n",
    "for epoch in range(100):\n",
    "    myoptimizer.zero_grad()\n",
    "    output=nueral_net.forward(n)\n",
    "    cost=cost_function(output,y)\n",
    "    cost.backward()\n",
    "    myoptimizer.step()\n",
    "    print(epoch,cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output=nueral_net.forward(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.2744388580322266\n"
     ]
    }
   ],
   "source": [
    "print(test_output.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-3.4128])\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.         -1.22474487  1.33630621]\n",
      " [ 1.22474487  0.         -0.26726124]\n",
      " [-1.22474487  1.22474487 -1.06904497]]\n",
      "[0. 0. 0.]\n",
      "[1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "X_train = np.array([[ 1., -1.,  2.], [ 2.,  0.,  0.],[ 0.,  1., -1.]])\n",
    "X_scaled = preprocessing.scale(X_train)\n",
    "print(X_scaled)\n",
    "print(X_scaled.mean(axis=0))\n",
    "print( X_scaled.std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.datasets\n",
    "import sklearn.model_selection\n",
    "np.random.seed(1)\n",
    "X, y = sklearn.datasets.fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-2132a220a582>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000, 784)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49000,)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Split: train\n",
      "    Root Location: ./data/\n",
      "    Transforms (if any): Compose(\n",
      "                             ToTensor()\n",
      "                             Normalize(mean=(0.1307,), std=(0.3081,))\n",
      "                         )\n",
      "    Target Transforms (if any): None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import torch.nn\n",
    "\n",
    "torch.random.manual_seed(1)\n",
    "\n",
    "batch_size_train = 64\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST(root='./data/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "print(train_loader.dataset)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 10000\n",
      "    Split: test\n",
      "    Root Location: ./data/\n",
      "    Transforms (if any): Compose(\n",
      "                             ToTensor()\n",
      "                             Normalize(mean=(0.1307,), std=(0.3081,))\n",
      "                         )\n",
      "    Target Transforms (if any): None\n"
     ]
    }
   ],
   "source": [
    "batch_size_test = 1000\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('./data/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)\n",
    "  \n",
    "print(test_loader.dataset)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEJhJREFUeJzt3X+s1fV9x/Hnq9quinRC+CEFrVZZY9dk6C4wY8tcTBurLaKLCukmxrhrZp2jzmykaHWbmLn015YpBicCG0pZBDToBGOWyWKnoiNCNSi1/kCugCJWrakK7/1xvzRHvOdzzj2/vufez+uR3Nxzzvt8v983B158v9/z/fFRRGBm+flE2Q2YWTkcfrNMOfxmmXL4zTLl8JtlyuE3y5TDb5Yph3+IkfROxc8BSe9VPP9Wh3v5tKSQNGkQ08yS9FNJb0nqk7RI0pHt7NMG5vAPMRFx1MEf4GXgmxWvrRjMvCQd3p4ukz4DfA84BvgS8DvATSX0kT2Hf5iRdLqkx4o1605JPzoY8oo19Z9L+jmwtXj9HEnPS9on6ceS/lfSn1TM83JJ2yTtlXS/pIlF6ZHi97Ziy2NWrf4iYnlEPBQR70XEG8AdwOkt/RCsLg7/8PMBcCUwGvgK8E3gskPe8w3g94FTJB0D/AT4DjAW2FnUAJA0G5hXzGc88H/AvxflGcXvLxRbHmsl/Vbxn0hPnf3OAH42uD+itUIZm33WRhHxeMXTn0v6V+APgdsqXl8YEfsAJP0p8ERErCuefx+4puK9lwM3RsRzRf1vgV9JGg+8NcDyfw0cXU+vkr4BXADU+x+FtZDX/MOMpC9K+k9JuyT9kv796zGHvO2VisefrXweEQeAVyvqnwNuK9bm+4A9wIdA3V/yVenzK8BSYFZE/KKZeVljHP7h53bgKeDEiPgM8HeADnlP5aWcfVQEWdIngIkV9VeASyLi6IqfIyLiyUPmUzdJ04HVwLciYmMj87DmOfzDz0jgrYh4R9LvAn9W4/33AdMlnV18MXg1MKqifhtwraQvAEgaJemP4Teb+G8Bn6+3OUmnAOuA3ohYX+901noO//DzHeAySe8At9D/ZV5VEdEHzAH+GXid/q2ALcCvi/rdwL8Aq4vdiM3AVytm8T3gP4rdgpnFF37vSJpaZZF/Tf+Xkf9WcX7Ck43+Ya1x8s08rFKx9n+N/vMHflp2P9Y+XvMbkr4u6bclfRq4HvgV4LXxMOfwG/Qfa/8FsBs4EzgvIt4vtyVrN2/2m2XKa36zTHX0DD9J3swwa7OIOPS8jgE1teaXdFZxwcd2SfObmZeZdVbD+/ySDgOeo/+Y7w7gCWBORDyTmMZrfrM268SafxqwPSJeKL4ZXgmc28T8zKyDmgn/RD56gcgOPnpOOACSeiVtkrSpiWWZWYs184XfQJsWH9usj4jFwGLwZr9ZN2lmzb8DOLbi+ST6bwRhZkNAM+F/Apgs6QRJnwJm03+FmJkNAQ1v9kfEh5KuBNYDhwFLIsK3YzIbIjp6eq/3+c3aryMn+ZjZ0OXwm2XK4TfLlMNvlimH3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTDr9Zpg5vZmJJLwJvA/uBDyOipxVNmVn7NRX+wh9FxOstmI+ZdZA3+80y1Wz4A9gg6UlJvQO9QVKvpE2SNjW5LDNrIUVE4xNLn42InZLGAQ8BfxERjyTe3/jCzKwuEaF63tfUmj8idha/dwNrgGnNzM/MOqfh8EsaIWnkwcfA14CtrWrMzNqrmW/7xwNrJB2cz10R8WBLurKWGTFiRLI+efLkZH3BggXJ+owZM5L1ZnYrH3300WT9/PPPb3je1kT4I+IF4Pda2IuZdZAP9ZllyuE3y5TDb5Yph98sUw6/WaZacWGPlWzKlClVa1dddVVy2osvvripZReHeqvavHlz1dq+ffuS05500knJ+qRJk5L1HTt2VK2NGzcuOe3cuXOT9QkTJiTrt956a7K+ffv2ZL0TvOY3y5TDb5Yph98sUw6/WaYcfrNMOfxmmXL4zTLV1J18Br0w38mnIbNmzUrWly9fXrV25JFHNrXsrVvTt2i46aabkvX777+/au3dd99NTlvrOP6ePXuS9enTp1et3Xzzzclpp06dmqzX8uabbybrY8eObWr+KR25k4+ZDV0Ov1mmHH6zTDn8Zply+M0y5fCbZcrhN8uUr+fvAqNHj07W16xZk6wfOHCgaq3WsfAHHnggWb/00kuT9XZKXY9fj9Q199OmpceX2bZtW8Pzhtp/p93Aa36zTDn8Zply+M0y5fCbZcrhN8uUw2+WKYffLFO+nr8DUvfVB1i5cmWyXmsY7dTfYa37z69YsSJZH8pSw5P39PQkp33mmWeS9S1btiTrY8aMSdYPP7x9p9i07Hp+SUsk7Za0teK10ZIekvR88XtUM82aWefVs9m/FDjrkNfmAw9HxGTg4eK5mQ0hNcMfEY8Aew95+VxgWfF4GZC+z5SZdZ1GdzzGR0QfQET0Sao68JmkXqC3weWYWZu0/cKeiFgMLIZ8v/Az60aNHurbJWkCQPF7d+taMrNOaDT89wEHjyHNBe5tTTtm1ik1j/NLuhs4AxgD7AKuB9YCq4DjgJeBCyLi0C8FB5rXsNzsr3VMt9Y186eeemqyvnr16mR94cKFVWu1jken7gWQs3POOSdZv/fe9PruvffeS9ZHjhw56J7qVe9x/pr7/BExp0rpzEF1ZGZdxaf3mmXK4TfLlMNvlimH3yxTDr9Zpnzr7jqNG1f1DGbWrVuXnLbWobwNGzYk6xdeeGGybq03c+bMpqZfunRpaxppI6/5zTLl8JtlyuE3y5TDb5Yph98sUw6/WaYcfrNM+Th/nRYtWlS1Vus4/s6dO5P1a665pqGerHG1PvNLLrkkWa/1d7px48bBttRxXvObZcrhN8uUw2+WKYffLFMOv1mmHH6zTDn8Zpnycf7CggULkvVZsxofjnDJkiXJeq3hoK0xd911V9XaRRdd1NS8H3/88WR91apVTc2/E7zmN8uUw2+WKYffLFMOv1mmHH6zTDn8Zply+M0yVXOI7pYurIuH6N6/f3+ynvqcli1blpx2/vz5yfqePXuS9VylxkoAuOKKK5L16667rmqt1r/7ofx3Wu8Q3TXX/JKWSNotaWvFazdIelXS5uLn7GaaNbPOq2ezfylw1gCv/ygiphQ/D7S2LTNrt5rhj4hHgL0d6MXMOqiZL/yulPR0sVswqtqbJPVK2iRpUxPLMrMWazT8i4ATgSlAH/CDam+MiMUR0RMRPQ0uy8zaoKHwR8SuiNgfEQeA24FprW3LzNqtofBLmlDx9Dxga7X3mll3qnk9v6S7gTOAMZJ2ANcDZ0iaAgTwInB5G3vsei+99FKy7uP4AxsxYkSy3tvbm6xfe+21yXrq3I1a91iodX+HN954I1kfCmqGPyLmDPDyHW3oxcw6yKf3mmXK4TfLlMNvlimH3yxTDr9Zpnzr7haoNVzzcFbrcN3s2bOr1ubNm5ec9uSTT07Wa33ul112WdXahg0bktPmwGt+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTPs7fAkcccUTZLTRs4sSJyfrMmTOT9auvvjpZP+GEEwbd00F33nlnsp66NTfAa6+91vCyc+A1v1mmHH6zTDn8Zply+M0y5fCbZcrhN8uUw2+WKQ/RXah1K+ajjz66bcteuXJlsj5p0qRk/emnn65amzYtPZ5KT09zAym9//77yfr69eur1m688cbktJs2eYS3RrRsiG4zG54cfrNMOfxmmXL4zTLl8JtlyuE3y5TDb5apmsf5JR0LLAeOAQ4AiyPinySNBn4CHE//MN0XRsSbNebVtcf5p0+fnqyvXbu2am3s2LGtbucjpPRh22bO1ag1fPgtt9ySrD/44IPJuo/Vd14rj/N/CPxVRJwM/AHwbUlfBOYDD0fEZODh4rmZDRE1wx8RfRHxVPH4beBZYCJwLrCseNsyYFa7mjSz1hvUPr+k44FTgMeA8RHRB/3/QQDjWt2cmbVP3ffwk3QUcA8wLyJ+WWs/tGK6XqC3sfbMrF3qWvNL+iT9wV8REauLl3dJmlDUJwC7B5o2IhZHRE9ENHcFiZm1VM3wq38VfwfwbET8sKJ0HzC3eDwXuLf17ZlZu9RzqO/LwEZgC/2H+gC+S/9+/yrgOOBl4IKI2FtjXl17qK+W1CW9p512WnLaqVOnNrXsWrtY27dvr1qrNRT1Bx98kKzv27cvWbfuU++hvpr7/BHxP0C1mZ05mKbMrHv4DD+zTDn8Zply+M0y5fCbZcrhN8uUw2+WKd+622yY8a27zSzJ4TfLlMNvlimH3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTDr9Zphx+s0w5/GaZqhl+ScdK+i9Jz0r6maS/LF6/QdKrkjYXP2e3v10za5Wag3ZImgBMiIinJI0EngRmARcC70TE9+temAftMGu7egftOLyOGfUBfcXjtyU9C0xsrj0zK9ug9vklHQ+cAjxWvHSlpKclLZE0qso0vZI2SdrUVKdm1lJ1j9Un6Sjgv4GFEbFa0njgdSCAv6d/1+DSGvPwZr9Zm9W72V9X+CV9ElgHrI+IHw5QPx5YFxFfqjEfh9+szVo2UKckAXcAz1YGv/gi8KDzgK2DbdLMylPPt/1fBjYCW4ADxcvfBeYAU+jf7H8RuLz4cjA1L6/5zdqspZv9reLwm7Vfyzb7zWx4cvjNMuXwm2XK4TfLlMNvlimH3yxTDr9Zphx+s0w5/GaZcvjNMuXwm2XK4TfLlMNvlimH3yxTNW/g2WKvAy9VPB9TvNaNurW3bu0L3FujWtnb5+p9Y0ev5//YwqVNEdFTWgMJ3dpbt/YF7q1RZfXmzX6zTDn8ZpkqO/yLS15+Srf21q19gXtrVCm9lbrPb2blKXvNb2YlcfjNMlVK+CWdJWmbpO2S5pfRQzWSXpS0pRh2vNTxBYsxEHdL2lrx2mhJD0l6vvg94BiJJfXWFcO2J4aVL/Wz67bh7ju+zy/pMOA54KvADuAJYE5EPNPRRqqQ9CLQExGlnxAiaQbwDrD84FBokv4R2BsR/1D8xzkqIv6mS3q7gUEO296m3qoNK38JJX52rRzuvhXKWPNPA7ZHxAsR8T6wEji3hD66XkQ8Auw95OVzgWXF42X0/+PpuCq9dYWI6IuIp4rHbwMHh5Uv9bNL9FWKMsI/EXil4vkOSvwABhDABklPSuotu5kBjD84LFrxe1zJ/Ryq5rDtnXTIsPJd89k1Mtx9q5UR/oGGEuqm442nR8SpwNeBbxebt1afRcCJ9I/h2Af8oMxmimHl7wHmRcQvy+yl0gB9lfK5lRH+HcCxFc8nATtL6GNAEbGz+L0bWEP/bko32XVwhOTi9+6S+/mNiNgVEfsj4gBwOyV+dsWw8vcAKyJidfFy6Z/dQH2V9bmVEf4ngMmSTpD0KWA2cF8JfXyMpBHFFzFIGgF8je4bevw+YG7xeC5wb4m9fES3DNtebVh5Sv7sum24+1LO8CsOZfwYOAxYEhELO97EACR9nv61PfRf7nxXmb1Juhs4g/5LPncB1wNrgVXAccDLwAUR0fEv3qr0dgaDHLa9Tb1VG1b+MUr87Fo53H1L+vHpvWZ58hl+Zply+M0y5fCbZcrhN8uUw2+WKYffLFMOv1mm/h+ssRKddbvGnAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "image = example_data[27][0]\n",
    "mean = 0.1307\n",
    "std = 0.3081\n",
    "image = ((mean * image) + std)\n",
    "plt.imshow(image,cmap='gray')\n",
    "plt.title(\"Target: {}\".format(example_targets[1]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x138cdf668>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_ = X_train[0].reshape((28,28))\n",
    "plt.imshow(img_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = torch.nn.Linear(28*28, 30)   #input size\n",
    "        self.fc2 = torch.nn.Linear(30, 30)\n",
    "        self.fc3 = torch.nn.Linear(30, 30)\n",
    "        self.fc4 = torch.nn.Linear(30, 10)\n",
    "        #self.fc5 = torch.nn.Linear(10,20)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)   # the size -1 is inferred from other dimensions (28*28)\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        #x = torch.sigmoid(self.fc4(x))\n",
    "        x = self.fc4(x)\n",
    "        return x     \n",
    "    \n",
    "    def training_phase(self, epoch, train_loader):\n",
    "        self.train()\n",
    "        train_loss = 0\n",
    "        train_corrects = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            optimiser.zero_grad()\n",
    "            output = self.forward(data)\n",
    "            _, preds = torch.max(output.data, 1)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            train_loss += loss.item()\n",
    "            train_corrects += torch.sum(preds == target.data) \n",
    "\n",
    "        epoch_acc= train_corrects.double() / len(train_loader.dataset)\n",
    "        print('Epoch {} , Average training loss is {:.6f} and accuracy is {}/{} {:.0f}%'.format((epoch+1),\n",
    "                        train_loss/len(train_loader),train_corrects.double(),\n",
    "                                        len(train_loader.dataset),epoch_acc*100.))\n",
    "        \n",
    "    def testing_phase(self, test_loader):\n",
    "        self.eval()\n",
    "        test_loss = 0\n",
    "        test_corrects = 0\n",
    "        total= 0\n",
    "        with torch.no_grad():\n",
    "            for batch_idx,(data, target) in enumerate(test_loader):\n",
    "                output = self.forward(data)\n",
    "                _, preds = torch.max(output.data, 1)\n",
    "                test_loss += criterion(output, target).item()\n",
    "                total += target.size(0)\n",
    "                test_corrects += torch.sum(preds == target.data) \n",
    "        \n",
    "            epoch_acc= test_corrects.double() / len(test_loader.dataset)\n",
    "            test_loss /= len(test_loader)\n",
    "       \n",
    "            print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "                test_loss, test_corrects, len(test_loader.dataset),\n",
    "                100. * epoch_acc))\n",
    "            scheduler.step(test_loss)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = ANN()\n",
    "learning_rate = 0.001\n",
    "optimiser = torch.optim.Adam(network.parameters(), lr=learning_rate, weight_decay=0.005) \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimiser,mode='min')\n",
    "criterion = torch.nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3221, Accuracy: 1032/10000 (10%)\n",
      "\n",
      "Epoch 1 , Average training loss is 0.943433 and accuracy is 42731.0/60000 71%\n",
      "\n",
      "Test set: Avg. loss: 0.4155, Accuracy: 8976/10000 (90%)\n",
      "\n",
      "Epoch 2 , Average training loss is 0.372447 and accuracy is 54347.0/60000 91%\n",
      "\n",
      "Test set: Avg. loss: 0.3244, Accuracy: 9191/10000 (92%)\n",
      "\n",
      "Epoch 3 , Average training loss is 0.319335 and accuracy is 55182.0/60000 92%\n",
      "\n",
      "Test set: Avg. loss: 0.2997, Accuracy: 9233/10000 (92%)\n",
      "\n",
      "Epoch 4 , Average training loss is 0.292971 and accuracy is 55667.0/60000 93%\n",
      "\n",
      "Test set: Avg. loss: 0.2817, Accuracy: 9289/10000 (93%)\n",
      "\n",
      "Epoch 5 , Average training loss is 0.278749 and accuracy is 55886.0/60000 93%\n",
      "\n",
      "Test set: Avg. loss: 0.2898, Accuracy: 9255/10000 (93%)\n",
      "\n",
      "Epoch 6 , Average training loss is 0.270325 and accuracy is 56040.0/60000 93%\n",
      "\n",
      "Test set: Avg. loss: 0.2630, Accuracy: 9366/10000 (94%)\n",
      "\n",
      "Epoch 7 , Average training loss is 0.266872 and accuracy is 56090.0/60000 93%\n",
      "\n",
      "Test set: Avg. loss: 0.2598, Accuracy: 9355/10000 (94%)\n",
      "\n",
      "Epoch 8 , Average training loss is 0.263369 and accuracy is 56135.0/60000 94%\n",
      "\n",
      "Test set: Avg. loss: 0.2538, Accuracy: 9340/10000 (93%)\n",
      "\n",
      "Epoch 9 , Average training loss is 0.262419 and accuracy is 56150.0/60000 94%\n",
      "\n",
      "Test set: Avg. loss: 0.2578, Accuracy: 9364/10000 (94%)\n",
      "\n",
      "Epoch 10 , Average training loss is 0.260037 and accuracy is 56182.0/60000 94%\n",
      "\n",
      "Test set: Avg. loss: 0.2646, Accuracy: 9349/10000 (93%)\n",
      "\n",
      "Epoch 11 , Average training loss is 0.259448 and accuracy is 56153.0/60000 94%\n",
      "\n",
      "Test set: Avg. loss: 0.2498, Accuracy: 9389/10000 (94%)\n",
      "\n",
      "Epoch 12 , Average training loss is 0.259012 and accuracy is 56253.0/60000 94%\n",
      "\n",
      "Test set: Avg. loss: 0.2502, Accuracy: 9370/10000 (94%)\n",
      "\n",
      "Epoch 13 , Average training loss is 0.258760 and accuracy is 56147.0/60000 94%\n",
      "\n",
      "Test set: Avg. loss: 0.2486, Accuracy: 9387/10000 (94%)\n",
      "\n",
      "Epoch 14 , Average training loss is 0.257014 and accuracy is 56250.0/60000 94%\n",
      "\n",
      "Test set: Avg. loss: 0.2593, Accuracy: 9344/10000 (93%)\n",
      "\n",
      "Epoch 15 , Average training loss is 0.256865 and accuracy is 56221.0/60000 94%\n",
      "\n",
      "Test set: Avg. loss: 0.2486, Accuracy: 9373/10000 (94%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 15\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]\n",
    "network.testing_phase(test_loader)\n",
    "for epoch in range(n_epochs):\n",
    "    network.training_phase(epoch, train_loader)\n",
    "    network.testing_phase(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0104,  0.0104,  0.0104,  ...,  0.0104,  0.0104,  0.0104],\n",
       "        [-0.0148, -0.0148, -0.0148,  ..., -0.0148, -0.0148, -0.0148],\n",
       "        [ 0.0058,  0.0058,  0.0058,  ...,  0.0058,  0.0058,  0.0058],\n",
       "        ...,\n",
       "        [-0.0041, -0.0041, -0.0041,  ..., -0.0041, -0.0041, -0.0041],\n",
       "        [ 0.0167,  0.0167,  0.0167,  ...,  0.0167,  0.0167,  0.0167],\n",
       "        [ 0.0177,  0.0177,  0.0177,  ...,  0.0177,  0.0177,  0.0177]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fc1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-2.4576e-02,  3.4788e-02, -1.3617e-02, -1.9362e-02,  3.9851e-02,\n",
       "         2.8848e-02,  6.4050e-05,  6.8984e-03, -3.0948e-02,  2.0166e-02,\n",
       "        -1.8748e-02,  4.9130e-03, -2.6641e-02, -2.6180e-03, -6.9148e-03,\n",
       "        -1.8571e-02,  3.1007e-03,  9.7134e-03, -4.6379e-03,  2.0403e-02,\n",
       "         1.1709e-02, -2.2196e-02, -1.6810e-02,  2.1868e-02,  1.8803e-02,\n",
       "         7.0316e-03,  1.9822e-02,  9.4324e-03, -3.9498e-02, -4.1801e-02],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.fc1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "examples = enumerate(train_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "example_data.shape\n",
    "\n",
    "with torch.no_grad():\n",
    "    example_network = network(example_data)   \n",
    "    _, example_pred = torch.max(example_network.data, 1)\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Target: \" + str(example_targets[i]) + \"\\n network: \" + str(example_pred.numpy()[i]) )\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
